{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255492cb-9932-485d-9918-86fdeac41019",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3487/23586936.py:2: FutureWarning: pyarrow.hdfs.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  hdfs.HadoopFileSystem(\"hdfs://namenode:9000\")\n"
     ]
    }
   ],
   "source": [
    "from pyarrow import fs, hdfs\n",
    "import pyarrow.csv as pv\n",
    "import collections\n",
    "import re\n",
    "from datetime import datetime\n",
    "hdfs.HadoopFileSystem(\"hdfs://namenode:9000\")\n",
    "connection = fs.HadoopFileSystem(host=\"namenode\", port=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5310794-b283-4bcf-ac42-87382bfdeae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FileInfo for '/pasta_avo1': type=FileType.Directory>,\n",
       " <FileInfo for '/pasta_avo1/sentiment140.csv': type=FileType.File, size=44326223>,\n",
       " <FileInfo for '/pasta_avo2': type=FileType.Directory>,\n",
       " <FileInfo for '/pasta_avo2/pasta_pai': type=FileType.Directory>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection.get_file_info(fs.FileSelector('/', recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4972a6b5-d58c-410e-8d52-6b95223f9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.create_dir('/pasta_avo1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c090278-731d-4a3d-a1cf-c33d3d00afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_path = '/home/jovyan/work/sentiment140.csv'\n",
    "destination_file_path = '/pasta_avo1/sentiment140.csv'\n",
    "\n",
    "with connection.open_output_stream(destination_file_path) as stream:\n",
    "    stream.write(open(source_file_path, 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ec84e15-c3d0-484b-a332-b6d355d8894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xef\\xbb\\xbftarget;ids;date;flag;user;text\\r\\n0;1467810369;Mon Apr 06 22:19:45 PDT 2009;NO_QUERY;_TheSpecialOne_;\"@switchfoot http://twitpic.com/2y1zl - Awww, that\\'s a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\\r\\n0;1467810672;Mon Apr 06 22:19:49 PDT 2009;NO_QUERY;scotthamilton;is upset that he can\\'t update his Facebook by texting it... and might cry as a result  School today also. Blah!\\r\\n0;1467810917;Mon Apr 06 22:19:53 PDT 2009;NO_QUERY;mattycus;@Kenichan I dived many times for the ball'\n"
     ]
    }
   ],
   "source": [
    "with connection.open_input_stream(destination_file_path) as f:\n",
    "    print(f.read(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a0b65c0-a847-438a-816e-916b9915e402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palavras mais frequentes\n",
      "i: 226118\n",
      "to: 127466\n",
      "the: 104841\n",
      "my: 74810\n",
      "a: 73919\n",
      "it: 63174\n",
      "and: 62151\n",
      "is: 52001\n",
      "t: 49829\n",
      "in: 46649\n"
     ]
    }
   ],
   "source": [
    "table = pv.read_csv(connection.open_input_file(destination_file_path), parse_options=pv.ParseOptions(delimiter=';'))\n",
    "\n",
    "tweets = table.column(5).to_pylist()\n",
    "\n",
    "word_counts = collections.Counter()\n",
    "\n",
    "for tweet in tweets:\n",
    "    words = re.findall(r'\\b\\w+\\b', tweet.lower())\n",
    "    word_counts.update(words)\n",
    "\n",
    "print(\"Palavras mais frequentes\")\n",
    "for word, count in word_counts.most_common(10):\n",
    "    print(f'{word}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb546a15-503e-419f-a859-349cae7dc9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios mais mencionados:\n",
      "@mileycyrus: 719\n",
      "@tommcfly: 664\n",
      "@ddlovato: 417\n",
      "@JonathanRKnight: 221\n",
      "@taylorswift13: 200\n",
      "@mitchelmusso: 192\n",
      "@DavidArchie: 185\n",
      "@jordanknight: 159\n",
      "@selenagomez: 144\n",
      "@DonnieWahlberg: 127\n"
     ]
    }
   ],
   "source": [
    "mention_counts = collections.Counter()\n",
    "\n",
    "for tweet in tweets:\n",
    "    mentions = re.findall(r'@\\w+', tweet)\n",
    "    mention_counts.update(mentions)\n",
    "\n",
    "print(\"Usuarios mais mencionados:\")\n",
    "for mention, count in mention_counts.most_common(10):\n",
    "    print(f'{mention}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81042154-d8b9-4e3b-8e7e-612b57acdc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hashtags mais frequentes:\n",
      "#fb: 373\n",
      "#fail: 115\n",
      "#asot400: 113\n",
      "#bgt: 73\n",
      "#1: 70\n",
      "#2: 64\n",
      "#followfriday: 61\n",
      "#NOME: 55\n",
      "#myweakness: 54\n",
      "#e3: 52\n"
     ]
    }
   ],
   "source": [
    "hashtag_counts = collections.Counter()\n",
    "\n",
    "for tweet in tweets:\n",
    "    hashtags = re.findall(r'#\\w+', tweet)\n",
    "    hashtag_counts.update(hashtags)\n",
    "\n",
    "print(\"Hashtags mais frequentes:\")\n",
    "for hashtag, count in hashtag_counts.most_common(10):\n",
    "    print(f'{hashtag}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320413d7-05f2-418a-9ae8-2b2f862838ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = table.column(3).to_pylist()\n",
    "days_of_week = [datetime.strptime(date, '%a %b %d %H:%M:%S PDT %Y').strftime('%A') for date in dates]\n",
    "words_by_day = {day: collections.Counter() for day in set(days_of_week)}\n",
    "\n",
    "for tweet, day in zip(tweets, days_of_week):\n",
    "    words = re.findall(r'\\b\\w+\\b', tweet.lower())\n",
    "    words_by_day[day].update(words)\n",
    "\n",
    "for day, counter in words_by_day.items():\n",
    "    print(f\"Palavras mais frequentes em {day}:\")\n",
    "    for word, count in counter.most_common(10):\n",
    "        print(f'{word}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d01a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_of_day = [datetime.strptime(date, '%a %b %d %H:%M:%S PDT %Y').strftime('%H') for date in dates]\n",
    "hashtags_by_hour = {hour: collections.Counter() for hour in set(hours_of_day)}\n",
    "\n",
    "for tweet, hour in zip(tweets, hours_of_day):\n",
    "    hashtags = re.findall(r'#\\w+', tweet)\n",
    "    hashtags_by_hour[hour].update(hashtags)\n",
    "\n",
    "for hour, counter in hashtags_by_hour.items():\n",
    "    print(f\"Hashtags mais frequentes na hora {hour}:00:\")\n",
    "    for hashtag, count in counter.most_common(10):\n",
    "        print(f'{hashtag}: {count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
